---
title: "lasso-pathwise-cv"
author: "Haotian Wu, Lin Yang"
date: "3/15/2022"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(tidyverse)
library(caret)
library(pROC)
library(glmnet)
```

## data import
```{r}
breast_dat = read_csv("breast-cancer.csv") %>% 
  select(-1, -33) %>% 
  janitor::clean_names() %>% 
  mutate(diagnosis = recode(diagnosis, "M" = 1, "B" = 0))


head(breast_dat, 5)
x <- breast_dat[2:31] #predictors
y <- breast_dat[1] #response
```

## coordinate-wise optimization of a logistic-lasso model
```{r}
#soft threshold
sfxn <- function(beta, lambda) {
  if (abs(beta) > lambda) {
    return(sign(beta) * (abs(beta) - lambda))
  }
  else {
    return(0)
  }
}
```

```{r}
#coordinate-wise optimization function
coordwise_lasso <- function(lambda, x, y, betastart, tol = exp(-10), maxiter = 1000) {
  x_standard <- cbind(rep(1, nrow(x)), scale(x)) #standardize data
  i <- 0
  n <- length(y)
  pnum <- length(betastart)
  betavec <- betastart
  loglik <- 0
  res <- c(0, loglik, betavec)
  prevloglik <- -Inf
  while (i < maxiter & abs(loglik - prevloglik) > tol & loglik < Inf) {
    i <- i + 1
    prevloglik <- loglik
    for (j in 1:pnum) {
      theta <- x_standard %*% betavec
      p <- exp(theta) / (1 + exp(theta)) #probability of malignant cases
      w <- p*(1-p) #working weights
      w <- ifelse(abs(w-0) < 1e-5, 1e-5, w)
      z <- theta + (y - p)/w #working response
      zwoj <- x_standard[, -j] %*% betavec[-j]
      betavec[j] <- sfxn(sum(w*(x_standard[,j])*(z - zwoj)), lambda) / (sum(w*x_standard[,j]*x_standard[,j]))
    }
    loglik <- sum(w*(z - x_standard %*% betavec)^2) / (2*n) + lambda * sum(abs(betavec))
    res <- rbind(res, c(i, loglik, betavec))
  }
  return(res)
}
coordwise_res <- coordwise_lasso(lambda = 2, x, y, betastart = rep(0, 31))
coordwise_res[nrow(coordwise_res), ]
```

We need to calculate lambdamax first to define a sequence of lambda. 
```{r}
x.matrix <- as.matrix(x)
#create a list to store for loop results
resls <- list()
lambdamax <- function(matrix, vector) {
  for (i in 1:ncol(matrix)) {
    res <- sum(matrix[, i] * y)
    resls[[i]] <- res
  }
  return(resls)
}

lambda_ls <- lambdamax(x.matrix, y) 
lambda_df <- as.data.frame(do.call(rbind, lambda_ls))
maxlambda <- max(lambda_ls) / nrow(y)
maxlambda

```


```{r}
#a path of solutions
pathwise <- function(x, y, lambda) {
  n <- length(lambda)
  betastart <- rep(0, 31)
  betas <- NULL
  for (i in 1:n) {
    coordwise_res <- coordwise_lasso(lambda = lambda[i],
                                     x = x,
                                     y = y,
                                     betastart = betastart)
    curbeta <- coordwise_res[nrow(coordwise_res), 3:33]
    betastart <- curbeta
    betas <- rbind(betas, c(curbeta))
  }
  return(data.frame(cbind(lambda, betas)))
}

pathwise_sol <- pathwise(x, y, lambda = seq(8, 0, length = 30))
pathwise_sol
```


## cross-validation

```{r}
#set.seed(8160)
#trnctl = trainControl(method = "cv", number = 5)
#
### lasso
#lasso_fit = train(x, y, method = "glmnet",
#               tuneGrid = expand.grid(alpha = 1, #lasso
#                                      lambda = exp(seq(4, -4, length = 50))),
#               trControl = trnctl)
#
#lasso_fit$bestTune

```



```{r cross validation}
set.seed(8160)

cv = function(data, lambda) {
  n <- nrow(data)
  data <- data[sample(n), ] #shuffle the data
<<<<<<< HEAD
  folds <- cut(seq(1, nrow(data)), breaks = 5, labels = FALSE) #Create 5 equal size folds
  mse <- data.frame() #a data frame storing mse results
  mse_lambda <- vector()
  #se <- vector() #a vector storing test errors
=======
  folds <- cut(seq(1, nrow(data)), breaks = 5, labels = FALSE) #Create 5 equally size folds
  res <- lambda 
  #se <- vector() #a vectro storing test errors
>>>>>>> 49daf33937ea5a03c050c3d41277725d3105fd5b
  
    #Perform 5 fold cross validation
  for (i in 1:5){
    #partition the data into train and test data
    testRows <- which(folds == i, arr.ind = TRUE)
    data_test <- data[testRows, ]
    data_train <- data[-testRows, ]
    x_train <- data_train[2:31]
    y_train <- data_train[1]
    x_test <- data_test[2:31]
    #standardized test data
    x_test_stan <- cbind(rep(1, nrow(x_test)), scale(x_test))
    y_test <- data_test %>% mutate(diagnosis = factor(diagnosis))
    y_test <- y_test$diagnosis
    #Use the test and train data partitions to perform lasso
    path_sol <- pathwise(x = x_train,
                         y = y_train,
                         lambda = lambda)
    print(path_sol)
    auc <- vector()
    for (j in 1:length(lambda)) {
      curbeta <- as.numeric(path_sol[j, 2:32])
      theta <- x_test_stan %*% curbeta
      p <- exp(theta) / (1 + exp(theta)) 
      auc[j] <- auc(y_test, p)
    }
    print(auc)
    res <- cbind(res, auc)
    print(res)
  }
  return(res)
    #se[j] <- sqrt(var(error)/5)
  #cv.auc.lambda <- rowMeans(mse)
  #return(cv.auc.lambda)
}

cv_test = cv(data = breast_dat, lambda = seq(5, 0, length = 5))
```

```{r}
#set.seed(2022)
#x.matrix <- as.matrix(x)
#y.matrix <- as.matrix(y)
#cv.lasso1 <- cv.glmnet(x.matrix, y.matrix, alpha = 1, family = "binomial", nfolds = 5)
#plot(cv.lasso1)
#lambda1 <- cv.lasso1$lambda.min
```



```{r}
#breast_dat[sample(nrow(breast_dat)), ]
#folds <- cut(seq(1, nrow(breast_dat)), breaks = 5, labels = FALSE)
#testIndexes = which(folds == 1, arr.ind = TRUE)
#x_train <- breast_dat[-testIndexes, 2:31]
#y_train <- breast_dat[-testIndexes, 1]
#x_test <- breast_dat[testIndexes, 2:31]
#x_test_stan <- cbind(rep(1, nrow(x_test)), scale(x_test))
#y_test <- breast_dat[testIndexes, ] %>% mutate(diagnosis = factor(diagnosis))
#y_test <- y_test$diagnosis
#aa <- coordwise_lasso(lambda = 0.5, x_train, y_train, betastart = rep(0, 31))
#a <- as.numeric(aa[nrow(aa), 3:33])
#theta1 <- x_test_stan %*% a
#p1 <- exp(theta1) / (1+exp(theta1))
#auc(y_test, p1)


```

