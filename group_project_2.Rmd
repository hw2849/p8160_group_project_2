---
title: "lasso-pathwise-cv"
author: "Haotian Wu, Lin Yang"
date: "3/15/2022"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(tidyverse)
library(caret)
library(cvAUC)
```

## data import
```{r}
breast_dat = read_csv("breast-cancer.csv") %>% 
  select(-1, -33) %>% 
  janitor::clean_names() %>% 
  mutate(diagnosis = recode(diagnosis, "M" = 1, "B" = 0))

head(breast_dat, 5)
x <- breast_dat[2:31] #predictors
y <- breast_dat[1] #response
```

## coordinate-wise optimization of a logistic-lasso model
```{r}
#soft threshold
sfxn <- function(beta, lambda) {
  if ((abs(beta) - lambda) > 0) {
    return(sign(beta) * (abs(beta) - lambda))
  }
  else {
    return(0)
  }
}
```

```{r}
#coordinate-wise optimization function
coordwise_lasso <- function(lambda, x, y, betastart, tol = exp(-10), maxiter = 1000) {
  x_standard <- cbind(rep(1, nrow(x)), scale(x)) #standardize data
  i <- 0
  n <- length(y)
  pnum <- length(betastart)
  betavec <- betastart
  loglik <- 0
  res <- c(0, loglik, betavec)
  prevloglik <- -Inf
  while (i < maxiter & abs(loglik - prevloglik) > tol & loglik < Inf) {
    i <- i + 1
    prevloglik <- loglik
    for (j in 1:pnum) {
      theta <- x_standard %*% betavec
      p <- exp(theta) / (1 + exp(theta)) #probability of malignant cases
      w <- p*(1-p) #working weights
      w <- ifelse(abs(w-0) < 1e-5, 1e-5, w)
      z <- theta + (y - p)/w #working response
      zwoj <- x_standard[, -j] %*% betavec[-j]
      betavec[j] <- sfxn(sum(w*(x_standard[,j])*(z - zwoj)), lambda) / (sum(w*x_standard[,j]*x_standard[,j]))
    }
    loglik <- sum(w*(z - x_standard %*% betavec)^2) / (2*n) + lambda * sum(abs(betavec))
    res <- rbind(res, c(i, loglik, betavec))
  }
  return(res)
}
coordwise_res <- coordwise_lasso(lambda = 2, x, y, betastart = rep(0, 31)) #include intercept?
coordwise_res[nrow(coordwise_res), ]
```

```{r}
#a path of solutions
pathwise <- function(x, y, lambda) {
  n <- length(lambda)
  betastart <- rep(0, 31)
  betas <- NULL
  for (i in 1:n) {
    coordwise_res <- coordwise_lasso(lambda = lambda[i],
                                     x = x,
                                     y = y,
                                     betastart = betastart)
    curbeta <- coordwise_res[nrow(coordwise_res), 3:33]
    betastart <- curbeta
    betas <- rbind(betas, c(curbeta))
  }
  return(data.frame(cbind(lambda, betas)))
}

pathwise_sol <- pathwise(x, y, lambda = exp(seq(4, -4, length = 30)))
```


```{r}
x.matrix <- as.matrix(x)
resls <- list()
lambdamax <- function(matrix, vector) {
  for (i in 1:ncol(matrix)) {
    res <- matrix[, i] * y
    maxres <- max(res)
    resls[[i]] <- maxres
  }
  return(resls)
}

lambdalist <- lambdamax(x.matrix, y) 
lambdadf <- as.data.frame(do.call(rbind, lambdalist))
maxlambda <- max(lambdadf$V1)
maxlambda
```




## cross-validation

```{r}
set.seed(8160)
trnctl = trainControl(method = "cv", number = 5)

## lasso
lasso_fit = train(x, y, method = "glmnet",
               tuneGrid = expand.grid(alpha = 1, #lasso
                                      lambda = exp(seq(4, -4, length = 50))),
               trControl = trnctl)

lasso_fit$bestTune

```

To perform a 5-fold cross validation, we first shuffle the original dataset randomly, and then split the dataset into (k=5) groups. Then for each group, take one group as a test data set and the rest groups as a training data set. Fitting a model on the training set and evaluate it on the test set. (https://machinelearningmastery.com/k-fold-cross-validation/)
k-fold cv code reference: (https://stats.stackexchange.com/questions/61090/how-to-split-a-data-set-to-do-10-fold-cross-validation)

```{r cross validation}
set.seed(8160)

cv = function(data, lambda, k) {
  data = data[sample(1:nrow(data)), ]
  
  #Create k equally size folds
  folds = cut(seq(1, nrow(data)), breaks = k,labels = FALSE)
  auc <- vector()
  se <- vector()

  for (j in 1:length(lambda)) {
    error = vector()
  
  #Perform 10 fold cross validation
  for(i in 1:k){
    start = rep(0, 31)
    
    #Segement data by fold using the which() function 
    testIndexes = which(folds == i, arr.ind = TRUE)
    testData = data[testIndexes, ]
    trainData = data[-testIndexes, ]
    
    #Use the test and train data partitions to perform lasso
    coordwise_res = coordwise_lasso(lambda = lambda[j],
                                     x = trainData$x,
                                     y = trainData$y,
                                     betastart = start)
    curbeta = coordwise_res[nrow(coordwise_res), 3:33]
    
    theta = as.matrix(testData$x) %*% as.matrix(curbeta)
    p = exp(theta) / (1 + exp(theta)) 
    error[i] = AUC(p, testData$y)
  }
    auc[j] = mean(error)
    se[j] = sqrt(var(error) / k)

  }
  return(cbind(lambda, auc, se))
}

cv_test = cv(data = breast_dat, lambda = exp(seq(4, -4, length = 30)), k = 5)
  
```

