---
title: "Project 2: Breast Cancer Diagnosis"
author: "Xinran Sun"
date: "3/17/2022"
header-includes:
   - \usepackage{amsmath}
output: pdf_document
---
# Objectives

A mammogram is an X-ray image of breast tissue. It can help save lives because it is easier to treat breast cancer in its early stages before the cancer is big enough to detect or cause symptoms. However, a wrong diagnosis can have a negative impact on patients. For example, if there is a false-positive test result, the doctor sees something that looks like cancer but is not. This could result in overtreatment that causes unnecessary side effects on patients. On the other hand, false-negative test result occurs when a doctor misses cancer tissues, which may delay the treatment. Therefore, building a model that gives an accurate classification of the tissue images is necessary to give proper treatment. In our study, we collected 569 images from both malignant and benign cancer tissues. Our goal is to build a predictive model to facilitate cancer diagnosis.

# Dataset

Our data set consistes of 569 rows, with 357 benign and 212 malignant. We denote 0 for benign and 1 for malignant. We also have 30 columns representing the features of the tissue images. They include the mean, standard deviation, and the largest values of the distributions of the following 10 features computed for the cell nuclei:
\begin{itemize}
\item radius (mean of distances from center to points on the perimeter)
\item texture (standard deviation of gray-scale values)
\item perimeter
\item area
\item smoothness (local variation in radius lengths)
\item compactness ($perimeter^2/area$ - 1.0)
\item concavity (severity of concave portions of the contour)
\item concave points (number of concave portions of the contour)
\item symmetry
\item fractal dimension ("coastline approximation" - 1)
\end{itemize}

### EDA

We built three feature plots to analyze the relationship between variables. 
The mean variables was plotted in first figure. From this plot, we can see that there are strong correlations between radius mean with perimeter mean and between radius mean with area mean. Perimeter mean and area mean also have strong correlation. Similarly, for the largest values, there are strong correlations between radius, perimeter and area. The correlations are reasonable because perimeter and area are calculated based on radius. 

For benign cases, all of the 10 features' means and largest values are smaller than malignant cases. 

# Methods


### Logistic Model

Let \textit{y} be the vector with 569 binary response variable, \textit{X} be the $569 \times 30$ matrix with 30 numerical explanatory variables, and \textit{$\beta$} be the vector with 30 corresponding coefficients. We also have \textit{$\beta_0$} as the intercepts.

For our logistic model, the probability of \textit{i}th row be a malignant tissue is given by:
\[P(y_i=1|X_i) = \frac{e^{\beta_0+\beta X_i}}{1+e^{\beta_0+\beta X_i}}.\]
For likelihood function is:
\[L(\beta_0,\beta) = \prod_{i=1}^n [(\frac{e^{\beta_0+\beta X_i}}{1+e^{\beta_0+\beta X_i}})^{y_i}(\frac{1}{1+e^{\beta_0+\beta X_i}})^{1-y_i}].\]
Maximizing the likelihood is equivalent to maximizing the log likelihood:
\[f(\beta_0,\beta) = \sum_{i=1}^n [y_i(\beta_0+\beta X_i)-\log(1+e^{\beta_0+\beta X_i})].\]
The gradient of this function is:
\[\nabla f(\beta_0,\beta)= \begin{pmatrix}
\sum_{i=1}^n y_i-p_i\\
\sum_{i=1}^n X_1(y_i-p_i)\\
...\\
\sum_{i=1}^n X_n(y_i-p_i)
\end{pmatrix} = X^T(y_i-p_i)\]
where $p_i = P(y_i=1|X_i)$ as mentioned in previous probability function.

The Hessian is given by
\[\nabla^2 f(\beta_0,\beta) = -X^TWX\]
where $W = p_i(1-p_i)$.

### Newton-Raphson Algorithm

### Path-wise Coordinate-wise Optimization Algorithm
To obtain a path of solutions with a descending sequence of $\lambda$â€™s in a logistic-LASSO model, we can implement a path-wise coordinate-wise optimization algorithm which contains the following steps:
\begin{itemize}
\item Step 1: Find the smallest value $\lambda$ for which all the estimated $\beta$ are 0, defined as $\lambda_{max}$.
\item Step 2: Define a fine sequence $\lambda_{max} \ge \lambda_1 \ge ... \lambda_{min} \ge 0$.
\item Step 3: To estimate coefficients for the current $\lambda_{k+1}$, implement coordinate descent algorithm using the computed coefficients of the previous $\lambda_{k}$ (warm start) as coefficient start values. 
\end{itemize}

# Results

# Conclusions


# Appendix

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(tidyverse)
library(caret)
library(ggcorrplot)
```

## data import and data clean
```{r}
#load the data
breast_dat = read.csv("breast-cancer.csv")[, -33] %>% 
  janitor::clean_names() %>% 
  mutate(diagnosis = recode(diagnosis, "M" = 1, "B" = 0))


head(breast_dat, 5)

r = dim(breast_dat)[1] #row number
c = dim(breast_dat)[2] #column number

var_names = names(breast_dat)[-c(1,2)] #variable names
  
standardize = function(col) {
  mean = mean(col)
  sd = sd(col)
  return((col - mean)/sd)
}

stand_df = breast_dat %>% 
  dplyr::select(radius_mean:fractal_dimension_worst) %>% 
  map_df(.x = ., standardize) #standardize

X = stand_df #predictors
y = as.vector(ifelse(breast_dat[,2] == "M", 1, 0))#response
```

## check collinearity

```{r}
corr = stand_df %>% 
  cor()

ggcorrplot(corr, type = "upper")

#X = stand_df %>% 
  #select(radius_mean, texture_mean, smoothness_mean, compactness_mean,
         #symmetry_mean, fractal_dimension_mean, radius_se, texture_se,
         #smoothness_se, concavity_se, symmetry_se)

#corr_new = X %>% cor()
#corr_new

#ggcorrplot(corr_new, type = "upper", lab = TRUE)
```

# feature plot

```{r}
data = cbind(y,X)

featurePlot(x = data[, 2:11],
            y = factor(data$y),
            plot = "pairs",
            auto.key = list(columns = 2)
)

featurePlot(x = data[, 12:21],
            y = factor(data$y),
            plot = "pairs",
            auto.key = list(columns = 2)
)

featurePlot(x = data[, 22:31],
            y = factor(data$y),
            plot = "pairs",
            auto.key = list(columns = 2)
)
```

```{r}
mean_data = breast_dat %>% 
  group_by(diagnosis) %>% 
  summarise(across(radius_mean: fractal_dimension_worst, ~ mean(.x, na.rm = TRUE)))
```

```{r}
log_model = glm(diagnosis ~ ., family = binomial("logit"), data  = breast_dat[, -1], start = rep(0, 31))
summary(log_model)
```


